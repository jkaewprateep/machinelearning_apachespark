# IBM - Machine Learning with Apache Spark - notes
Implementing machine learning using Apache Spark

## ğŸ§¸ğŸ’¬ Before we start

ğŸ§¸ğŸ’¬ Before we start understanding the basic concept of working sessions with Apache Spark, it is the same as Tensorflow and distributed processes machine learning and remote tasks executions solution. </br>
ğŸ‘ğŸ’¬ â° Apache Spake is a network application capable of network routes and application implementation with supporting programming languages such as angular.js, Python, Pytorch, Java, Javascript, machine learning APIs, and data scientific APIs. </br>
ğŸ¦¤ğŸ’¬ The remote execution tasks and synchronized are important in the research study too, we measure the abandoned executions for solution performance while remote execution can work parallel for verification methods for some execution tasks verification with the same or different process execution as we know EDW data warehouse processes. ğŸ—ºï¸ğŸ’¬ See you in the next 6 hours from Australia. </br>

```
import findspark
findspark.init()

from pyspark.sql import SparkSession
```

## ETL processes

## Word phase tokenizers

## NLTK and implementation

## The n-grams word tokenizers and speech engine processing

## Attention networks
